{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#=====================================================#\n",
    "# Function for time\n",
    "#=====================================================#\n",
    "def convert(seconds): \n",
    "    seconds = seconds % (24 * 3600) \n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "      \n",
    "    return \"%d:%02d:%02d\" % (hour, minutes, seconds) \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#=====================================================#\n",
    "# Extract details from csv file\n",
    "#=====================================================#\n",
    "data = pd.read_csv('reviews.csv',index_col=[0])\n",
    "data = data.fillna('-') # fill none with '-'\n",
    "data.replace({'\\n': ''}, inplace=True, regex=True) # remove break line\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#=====================================================#\n",
    "# Extract details from pkl file\n",
    "#=====================================================#\n",
    "data = pd.read_pickle(\"restaurant_reviews.pkl\")\n",
    "data = data.fillna('-') # fill none with '-'\n",
    "data.replace({'\\n': ''}, inplace=True, regex=True) # remove break line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create column for food names per review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1:03:11\n"
     ]
    }
   ],
   "source": [
    "#=====================================================#\n",
    "# Extract food names from text file\n",
    "#=====================================================#\n",
    "start = time.time()\n",
    "\n",
    "with open('food_list_V1.txt',encoding=\"utf8\") as f:\n",
    "    food_list = [x.strip() for x in f.readlines()]\n",
    "\n",
    "food_tag_list = []\n",
    "for i in range(data.shape[0]):\n",
    "    rev = data['Body'].iloc[i]\n",
    "    #rev = rev.replace('and ', '').replace('& ', '')\n",
    "    doc = nlp(rev)\n",
    "    tag = []  \n",
    "    food_tag = []\n",
    "    \n",
    "    # For each word in the review\n",
    "    for food in food_list:\n",
    "        if food in doc.text:\n",
    "            food_tag.append(food)\n",
    "    food_tag_list.append(','.join(food_tag))\n",
    "\n",
    "#=====================================================#\n",
    "# Store food name into dataframe\n",
    "#=====================================================#\n",
    "data['Food'] = food_tag_list\n",
    "\n",
    "print('Time taken:', convert(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Reviewer_Level</th>\n",
       "      <th>Reviewer_NumReviews</th>\n",
       "      <th>ReviewDateTime</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Glad It’s Back!</td>\n",
       "      <td>We ordered two appetisers and four main dishes...</td>\n",
       "      <td>Sofina Ng</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10m ago</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>beer,fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Yuzu Ochazuke ($24)</td>\n",
       "      <td>This rice in soup dish is the first one I’ve h...</td>\n",
       "      <td>Jan L</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Belly Roll Mee ($15)</td>\n",
       "      <td>The successor to Uncle Kiisu, Babasan’s menu d...</td>\n",
       "      <td>Dex Neo</td>\n",
       "      <td>8</td>\n",
       "      <td>958</td>\n",
       "      <td>Oct 24 at 5:42pm</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>crispy pork,mee siam,pork,pork belly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Samurai Kueh Pie Tee</td>\n",
       "      <td>This was like a little bomb that exploded with...</td>\n",
       "      <td>Komal Salve</td>\n",
       "      <td>7</td>\n",
       "      <td>208</td>\n",
       "      <td>Oct 23 at 10:06am</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>fish,fish roe,rice,roe,seafood,unagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Build Your Own Bowl (Small)</td>\n",
       "      <td>Most salad/grain bowls serve up similar stuff ...</td>\n",
       "      <td>Nom Nom</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Oct 25 at 10:13pm</td>\n",
       "      <td>/yobo</td>\n",
       "      <td>brown rice,cream,pumpkin,rice,salad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Yummy meat galore shabu shabu buffet for the s...</td>\n",
       "      <td>Yummy meat galore shabu shabu buffet for the s...</td>\n",
       "      <td>Alison Ong</td>\n",
       "      <td>7</td>\n",
       "      <td>229</td>\n",
       "      <td>Dec 16, 2013</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td>earl,meat,shabu shabu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Our #steamboat #buffet #dinner before watching...</td>\n",
       "      <td>Our #steamboat #buffet #dinner before watching...</td>\n",
       "      <td>Benjamin Yeo</td>\n",
       "      <td>6</td>\n",
       "      <td>170</td>\n",
       "      <td>Jun 7, 2013</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td>steamboat,tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>My favorite whenever im here for steamboat! Lo...</td>\n",
       "      <td></td>\n",
       "      <td>June Lee</td>\n",
       "      <td>8</td>\n",
       "      <td>989</td>\n",
       "      <td>Aug 29, 2012</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Sukiyaki and Kimchi Based Hotpot Buffet</td>\n",
       "      <td></td>\n",
       "      <td>Jasmine Low</td>\n",
       "      <td>6</td>\n",
       "      <td>187</td>\n",
       "      <td>Aug 28, 2012</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>My Must Have Whenever I'm Here For Steamboat</td>\n",
       "      <td></td>\n",
       "      <td>June Lee</td>\n",
       "      <td>8</td>\n",
       "      <td>989</td>\n",
       "      <td>Jun 29, 2012</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63921 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                     Glad It’s Back!   \n",
       "1                                 Yuzu Ochazuke ($24)   \n",
       "2                                Belly Roll Mee ($15)   \n",
       "3                                Samurai Kueh Pie Tee   \n",
       "0                         Build Your Own Bowl (Small)   \n",
       "..                                                ...   \n",
       "7   Yummy meat galore shabu shabu buffet for the s...   \n",
       "8   Our #steamboat #buffet #dinner before watching...   \n",
       "9   My favorite whenever im here for steamboat! Lo...   \n",
       "10            Sukiyaki and Kimchi Based Hotpot Buffet   \n",
       "11       My Must Have Whenever I'm Here For Steamboat   \n",
       "\n",
       "                                                 Body      Reviewer  \\\n",
       "0   We ordered two appetisers and four main dishes...     Sofina Ng   \n",
       "1   This rice in soup dish is the first one I’ve h...         Jan L   \n",
       "2   The successor to Uncle Kiisu, Babasan’s menu d...       Dex Neo   \n",
       "3   This was like a little bomb that exploded with...   Komal Salve   \n",
       "0   Most salad/grain bowls serve up similar stuff ...       Nom Nom   \n",
       "..                                                ...           ...   \n",
       "7   Yummy meat galore shabu shabu buffet for the s...    Alison Ong   \n",
       "8   Our #steamboat #buffet #dinner before watching...  Benjamin Yeo   \n",
       "9                                                          June Lee   \n",
       "10                                                      Jasmine Low   \n",
       "11                                                         June Lee   \n",
       "\n",
       "   Reviewer_Level Reviewer_NumReviews     ReviewDateTime  \\\n",
       "0               3                   9            10m ago   \n",
       "1               3                  10             5d ago   \n",
       "2               8                 958   Oct 24 at 5:42pm   \n",
       "3               7                 208  Oct 23 at 10:06am   \n",
       "0               3                  15  Oct 25 at 10:13pm   \n",
       "..            ...                 ...                ...   \n",
       "7               7                 229       Dec 16, 2013   \n",
       "8               6                 170        Jun 7, 2013   \n",
       "9               8                 989       Aug 29, 2012   \n",
       "10              6                 187       Aug 28, 2012   \n",
       "11              8                 989       Jun 29, 2012   \n",
       "\n",
       "                 Restaurant                                  Food  \n",
       "0   /babasan-by-uncle-kiisu                            beer,fruit  \n",
       "1   /babasan-by-uncle-kiisu                                  rice  \n",
       "2   /babasan-by-uncle-kiisu  crispy pork,mee siam,pork,pork belly  \n",
       "3   /babasan-by-uncle-kiisu  fish,fish roe,rice,roe,seafood,unagi  \n",
       "0                     /yobo   brown rice,cream,pumpkin,rice,salad  \n",
       "..                      ...                                   ...  \n",
       "7                   /sukiya                 earl,meat,shabu shabu  \n",
       "8                   /sukiya                         steamboat,tea  \n",
       "9                   /sukiya                                        \n",
       "10                  /sukiya                                        \n",
       "11                  /sukiya                                        \n",
       "\n",
       "[63921 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create columns for restaurant and food reviews by splitting full reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1:05:16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Reviewer_Level</th>\n",
       "      <th>Reviewer_NumReviews</th>\n",
       "      <th>ReviewDateTime</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Food</th>\n",
       "      <th>RestaurantReview</th>\n",
       "      <th>FoodReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Glad It’s Back!</td>\n",
       "      <td>We ordered two appetisers and four main dishes...</td>\n",
       "      <td>Sofina Ng</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10m ago</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>beer,fruit</td>\n",
       "      <td>we ordered two appetisers and four main dishes...</td>\n",
       "      <td>kronenbourg blanc beer was very enjoyable too....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Yuzu Ochazuke ($24)</td>\n",
       "      <td>This rice in soup dish is the first one I’ve h...</td>\n",
       "      <td>Jan L</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>rice</td>\n",
       "      <td>boy did it impress! perfect harmonious blend o...</td>\n",
       "      <td>this rice in soup dish is the first one i’ve h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Belly Roll Mee ($15)</td>\n",
       "      <td>The successor to Uncle Kiisu, Babasan’s menu d...</td>\n",
       "      <td>Dex Neo</td>\n",
       "      <td>8</td>\n",
       "      <td>958</td>\n",
       "      <td>Oct 24 at 5:42pm</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>crispy pork,mee siam,pork,pork belly</td>\n",
       "      <td>the successor to uncle kiisu, babasan’s menu d...</td>\n",
       "      <td>i was seriously wondering how they would pull ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Samurai Kueh Pie Tee</td>\n",
       "      <td>This was like a little bomb that exploded with...</td>\n",
       "      <td>Komal Salve</td>\n",
       "      <td>7</td>\n",
       "      <td>208</td>\n",
       "      <td>Oct 23 at 10:06am</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>fish,fish roe,rice,roe,seafood,unagi</td>\n",
       "      <td>this was like a little bomb that exploded with...</td>\n",
       "      <td>i'm not a big fan of the seafoody taste loved ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Build Your Own Bowl (Small)</td>\n",
       "      <td>Most salad/grain bowls serve up similar stuff ...</td>\n",
       "      <td>Nom Nom</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Oct 25 at 10:13pm</td>\n",
       "      <td>/yobo</td>\n",
       "      <td>brown rice,cream,pumpkin,rice,salad</td>\n",
       "      <td>but i really enjoyed the broccoli puree served...</td>\n",
       "      <td>most salad/grain bowls serve up similar stuff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Yummy meat galore shabu shabu buffet for the s...</td>\n",
       "      <td>Yummy meat galore shabu shabu buffet for the s...</td>\n",
       "      <td>Alison Ong</td>\n",
       "      <td>7</td>\n",
       "      <td>229</td>\n",
       "      <td>Dec 16, 2013</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td>earl,meat,shabu shabu</td>\n",
       "      <td></td>\n",
       "      <td>yummy meat galore shabu shabu buffet for the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Our #steamboat #buffet #dinner before watching...</td>\n",
       "      <td>Our #steamboat #buffet #dinner before watching...</td>\n",
       "      <td>Benjamin Yeo</td>\n",
       "      <td>6</td>\n",
       "      <td>170</td>\n",
       "      <td>Jun 7, 2013</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td>steamboat,tea</td>\n",
       "      <td>our    before watching</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>My favorite whenever im here for steamboat! Lo...</td>\n",
       "      <td></td>\n",
       "      <td>June Lee</td>\n",
       "      <td>8</td>\n",
       "      <td>989</td>\n",
       "      <td>Aug 29, 2012</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Sukiyaki and Kimchi Based Hotpot Buffet</td>\n",
       "      <td></td>\n",
       "      <td>Jasmine Low</td>\n",
       "      <td>6</td>\n",
       "      <td>187</td>\n",
       "      <td>Aug 28, 2012</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>My Must Have Whenever I'm Here For Steamboat</td>\n",
       "      <td></td>\n",
       "      <td>June Lee</td>\n",
       "      <td>8</td>\n",
       "      <td>989</td>\n",
       "      <td>Jun 29, 2012</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63921 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                     Glad It’s Back!   \n",
       "1                                 Yuzu Ochazuke ($24)   \n",
       "2                                Belly Roll Mee ($15)   \n",
       "3                                Samurai Kueh Pie Tee   \n",
       "0                         Build Your Own Bowl (Small)   \n",
       "..                                                ...   \n",
       "7   Yummy meat galore shabu shabu buffet for the s...   \n",
       "8   Our #steamboat #buffet #dinner before watching...   \n",
       "9   My favorite whenever im here for steamboat! Lo...   \n",
       "10            Sukiyaki and Kimchi Based Hotpot Buffet   \n",
       "11       My Must Have Whenever I'm Here For Steamboat   \n",
       "\n",
       "                                                 Body      Reviewer  \\\n",
       "0   We ordered two appetisers and four main dishes...     Sofina Ng   \n",
       "1   This rice in soup dish is the first one I’ve h...         Jan L   \n",
       "2   The successor to Uncle Kiisu, Babasan’s menu d...       Dex Neo   \n",
       "3   This was like a little bomb that exploded with...   Komal Salve   \n",
       "0   Most salad/grain bowls serve up similar stuff ...       Nom Nom   \n",
       "..                                                ...           ...   \n",
       "7   Yummy meat galore shabu shabu buffet for the s...    Alison Ong   \n",
       "8   Our #steamboat #buffet #dinner before watching...  Benjamin Yeo   \n",
       "9                                                          June Lee   \n",
       "10                                                      Jasmine Low   \n",
       "11                                                         June Lee   \n",
       "\n",
       "   Reviewer_Level Reviewer_NumReviews     ReviewDateTime  \\\n",
       "0               3                   9            10m ago   \n",
       "1               3                  10             5d ago   \n",
       "2               8                 958   Oct 24 at 5:42pm   \n",
       "3               7                 208  Oct 23 at 10:06am   \n",
       "0               3                  15  Oct 25 at 10:13pm   \n",
       "..            ...                 ...                ...   \n",
       "7               7                 229       Dec 16, 2013   \n",
       "8               6                 170        Jun 7, 2013   \n",
       "9               8                 989       Aug 29, 2012   \n",
       "10              6                 187       Aug 28, 2012   \n",
       "11              8                 989       Jun 29, 2012   \n",
       "\n",
       "                 Restaurant                                  Food  \\\n",
       "0   /babasan-by-uncle-kiisu                            beer,fruit   \n",
       "1   /babasan-by-uncle-kiisu                                  rice   \n",
       "2   /babasan-by-uncle-kiisu  crispy pork,mee siam,pork,pork belly   \n",
       "3   /babasan-by-uncle-kiisu  fish,fish roe,rice,roe,seafood,unagi   \n",
       "0                     /yobo   brown rice,cream,pumpkin,rice,salad   \n",
       "..                      ...                                   ...   \n",
       "7                   /sukiya                 earl,meat,shabu shabu   \n",
       "8                   /sukiya                         steamboat,tea   \n",
       "9                   /sukiya                                         \n",
       "10                  /sukiya                                         \n",
       "11                  /sukiya                                         \n",
       "\n",
       "                                     RestaurantReview  \\\n",
       "0   we ordered two appetisers and four main dishes...   \n",
       "1   boy did it impress! perfect harmonious blend o...   \n",
       "2   the successor to uncle kiisu, babasan’s menu d...   \n",
       "3   this was like a little bomb that exploded with...   \n",
       "0   but i really enjoyed the broccoli puree served...   \n",
       "..                                                ...   \n",
       "7                                                       \n",
       "8                            our    before watching     \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "\n",
       "                                           FoodReview  \n",
       "0   kronenbourg blanc beer was very enjoyable too....  \n",
       "1   this rice in soup dish is the first one i’ve h...  \n",
       "2   i was seriously wondering how they would pull ...  \n",
       "3   i'm not a big fan of the seafoody taste loved ...  \n",
       "0   most salad/grain bowls serve up similar stuff ...  \n",
       "..                                                ...  \n",
       "7   yummy meat galore shabu shabu buffet for the s...  \n",
       "8                                                      \n",
       "9                                                      \n",
       "10                                                     \n",
       "11                                                     \n",
       "\n",
       "[63921 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=====================================================#\n",
    "# Extract restaurant and food reviews\n",
    "#=====================================================#\n",
    "start = time.time()\n",
    "\n",
    "## Function set custom boundaries to break into phases or sentences\n",
    "def set_custom_boundaries(doc):\n",
    "    link_words = ['but','however','unlike', 'even though', 'despite', 'in spite of', 'unlike', 'whereas', 'while']\n",
    "    for token in doc[:-1]:\n",
    "        if token.text in link_words:\n",
    "            doc[token.i].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "## Set spacy pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(set_custom_boundaries, before=\"parser\")\n",
    "\n",
    "## Get Restaurant and Food reviews\n",
    "res_rev_list = []\n",
    "food_rev_list = []\n",
    "for i in range(data.shape[0]):\n",
    "    rev = data['Body'].iloc[i]\n",
    "    rev = re.sub(r'[@#]\\w+', '', rev) # remove hashtag\n",
    "    doc = nlp(rev)\n",
    "    glist = []\n",
    "    flist = []\n",
    "    for sent in doc.sents: # for each phase/sentence\n",
    "        glist.append(sent.text.lower()) # add all phase/sentence to generic list\n",
    "        for s in food_list: # for each food name\n",
    "            if s in sent.text.lower(): # check if food name appear in phase/sentence\n",
    "                flist.append(sent.text.lower()) # add phase/sentence with food name to food list\n",
    "                try:\n",
    "                    glist.remove(sent.text.lower()) # remove phase/sentence with food name from generic list\n",
    "                except:\n",
    "                    pass\n",
    "    flist=list(dict.fromkeys(flist)) # remove duplicates\n",
    "    glist=list(dict.fromkeys(glist)) # remove duplicates\n",
    "    food_rev_list.append(' '.join(flist))\n",
    "    res_rev_list.append(' '.join(glist))\n",
    "\n",
    "\n",
    "#=====================================================#\n",
    "# Store segmented reviews into dataframe\n",
    "#=====================================================#\n",
    "data['RestaurantReview'] = res_rev_list\n",
    "data['FoodReview'] = food_rev_list\n",
    "\n",
    "print('Time taken:', convert(time.time()-start))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features using spaCy- POS tag and Dependency parser\n",
    "spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more.\n",
    "- https://spacy.io/usage/linguistic-features#pos-tagging\n",
    "- https://spacy.io/usage/linguistic-features#dependency-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================#\n",
    "# Extract features from reviews\n",
    "#=====================================================#\n",
    "\n",
    "# Get list of words to be removed from reviews\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "remove_words = [\"n't\",\"'m\",\"'s\",\"'ll\",\"'ve\",\"'d\",\"'re\",\"n’t\",\"’m\",\"’s\",\"’ll\",\"’ve\",\"’d\",\"’re\"]\n",
    "\n",
    "def features_spacy(col_name):\n",
    "    # For each word in the review\n",
    "    feature_list = []\n",
    "    text_list = []\n",
    "    pos_list = []\n",
    "    dep_list = []\n",
    "    #dep_head_list=[]\n",
    "    #dep_child_list=[]\n",
    "    #dep_head_pos_list=[]\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        rev = data[col_name].iloc[i]\n",
    "        rev = rev.replace('and ', '').replace('& ', '')\n",
    "        doc = nlp(rev)\n",
    "        feature = []    \n",
    "\n",
    "        # For each word in the review\n",
    "        for w in doc:\n",
    "\n",
    "            # Check if word not from stop words\n",
    "            if w.text.lower() not in stop_words and w.text.lower() not in remove_words:\n",
    "                extract = None\n",
    "                text_list.append(w.text.lower())\n",
    "                pos_list.append(w.pos_)\n",
    "                dep_list.append(w.dep_)\n",
    "                #dep_head_list.append(w.head.text)\n",
    "                #dep_head_pos_list.append(w.head.pos_)\n",
    "                #dep_child_list.append([child for child in w.children])\n",
    "\n",
    "                # Check for more than two words    \n",
    "                if len(text_list) > 2: \n",
    "\n",
    "                    # Rule 1 => e.g. 'affordable', 'appetising'\n",
    "                    if w.pos_ in ['ADJ', 'VERB'] or w.dep_ == \"amod\": #and w.head.pos_ in ['NOUN']:\n",
    "                        extract = text_list[-1]\n",
    "\n",
    "                    # Rule 2 => e.g. 'not good', 'really affordable'\n",
    "                    if w.pos_ in ['ADJ', 'VERB'] and pos_list[-2] in ['ADV']: # and w.head.pos_ in ['NOUN']:\n",
    "                        extract = text_list[-2] + ' ' + text_list[-1]\n",
    "\n",
    "                    # Rule 3 => e.g. 'not the best'\n",
    "                    if w.pos_ in ['ADJ', 'VERB'] and pos_list[-2] in ['DET'] and pos_list[-3] in ['ADV']: # and w.head.pos_ in ['NOUN']:\n",
    "                        extract = text_list[-3] + ' ' + text_list[-2] + ' ' + text_list[-1]\n",
    "\n",
    "                    # Rule 4 => e.g. 'not too good'\n",
    "                    if w.pos_ in ['ADJ', 'VERB'] and pos_list[-2] in ['ADV'] and pos_list[-3] in ['ADV']: # and w.head.pos_ in ['NOUN']:\n",
    "                        extract = text_list[-3] + ' ' + text_list[-2] + ' ' + text_list[-1]\n",
    "\n",
    "                    if extract != None:\n",
    "                        feature.append(extract)\n",
    "                        \n",
    "        feature = list(dict.fromkeys(feature)) # remove duplicates\n",
    "        feature_list.append(','.join(feature)) # create list of sentiment feature for each review\n",
    "        \n",
    "    return feature_list\n",
    "\n",
    "\n",
    "#=====================================================#\n",
    "# Store features into dataframe\n",
    "#=====================================================#\n",
    "start = time.time()\n",
    "\n",
    "data['RestaurantFeature(spacy)'] = features_spacy('RestaurantReview')\n",
    "data['FoodFeature(spacy)'] = features_spacy('FoodReview')\n",
    "\n",
    "print('Time taken:', convert(time.time()-start))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0:16:18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Reviewer_Level</th>\n",
       "      <th>Reviewer_NumReviews</th>\n",
       "      <th>ReviewDateTime</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Food</th>\n",
       "      <th>RestaurantReview</th>\n",
       "      <th>FoodReview</th>\n",
       "      <th>RestaurantFeature(spacy)</th>\n",
       "      <th>FoodFeature(spacy)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Glad It’s Back!</td>\n",
       "      <td>We ordered two appetisers and four main dishes...</td>\n",
       "      <td>Sofina Ng</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10m ago</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>beer,fruit</td>\n",
       "      <td>we ordered two appetisers and four main dishes...</td>\n",
       "      <td>kronenbourg blanc beer was very enjoyable too....</td>\n",
       "      <td>main,unique,boasting,manifested,creative,strong</td>\n",
       "      <td>enjoyable,sweet,mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Yuzu Ochazuke ($24)</td>\n",
       "      <td>This rice in soup dish is the first one I’ve h...</td>\n",
       "      <td>Jan L</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>rice</td>\n",
       "      <td>boy did it impress! perfect harmonious blend o...</td>\n",
       "      <td>this rice in soup dish is the first one i’ve h...</td>\n",
       "      <td>impress,perfect,harmonious,fresh,generous,serv...</td>\n",
       "      <td>great,good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Belly Roll Mee ($15)</td>\n",
       "      <td>The successor to Uncle Kiisu, Babasan’s menu d...</td>\n",
       "      <td>Dex Neo</td>\n",
       "      <td>8</td>\n",
       "      <td>958</td>\n",
       "      <td>Oct 24 at 5:42pm</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>crispy pork,mee siam,pork,pork belly</td>\n",
       "      <td>the successor to uncle kiisu, babasan’s menu d...</td>\n",
       "      <td>i was seriously wondering how they would pull ...</td>\n",
       "      <td>dreamt,good,sounds,heavy,provided,cut,amazingl...</td>\n",
       "      <td>seriously wondering,pull,crispy,stuffed,tender...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Samurai Kueh Pie Tee</td>\n",
       "      <td>This was like a little bomb that exploded with...</td>\n",
       "      <td>Komal Salve</td>\n",
       "      <td>7</td>\n",
       "      <td>208</td>\n",
       "      <td>Oct 23 at 10:06am</td>\n",
       "      <td>/babasan-by-uncle-kiisu</td>\n",
       "      <td>fish,fish roe,rice,roe,seafood,unagi</td>\n",
       "      <td>this was like a little bomb that exploded with...</td>\n",
       "      <td>i'm not a big fan of the seafoody taste loved ...</td>\n",
       "      <td>little,exploded,eating,try,super worth</td>\n",
       "      <td>big,loved,flying,smooth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Build Your Own Bowl (Small)</td>\n",
       "      <td>Most salad/grain bowls serve up similar stuff ...</td>\n",
       "      <td>Nom Nom</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Oct 25 at 10:13pm</td>\n",
       "      <td>/yobo</td>\n",
       "      <td>brown rice,cream,pumpkin,rice,salad</td>\n",
       "      <td>but i really enjoyed the broccoli puree served...</td>\n",
       "      <td>most salad/grain bowls serve up similar stuff ...</td>\n",
       "      <td>enjoyed,served</td>\n",
       "      <td>salad,serve,similar,creamy,paired,brown,roaste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Yummy meat galore shabu shabu buffet for the s...</td>\n",
       "      <td>Yummy meat galore shabu shabu buffet for the s...</td>\n",
       "      <td>Alison Ong</td>\n",
       "      <td>7</td>\n",
       "      <td>229</td>\n",
       "      <td>Dec 16, 2013</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td>earl,meat,shabu shabu</td>\n",
       "      <td></td>\n",
       "      <td>yummy meat galore shabu shabu buffet for the s...</td>\n",
       "      <td></td>\n",
       "      <td>early,b4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Our #steamboat #buffet #dinner before watching...</td>\n",
       "      <td>Our #steamboat #buffet #dinner before watching...</td>\n",
       "      <td>Benjamin Yeo</td>\n",
       "      <td>6</td>\n",
       "      <td>170</td>\n",
       "      <td>Jun 7, 2013</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td>steamboat,tea</td>\n",
       "      <td>our    before watching</td>\n",
       "      <td></td>\n",
       "      <td>watching</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>My favorite whenever im here for steamboat! Lo...</td>\n",
       "      <td></td>\n",
       "      <td>June Lee</td>\n",
       "      <td>8</td>\n",
       "      <td>989</td>\n",
       "      <td>Aug 29, 2012</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Sukiyaki and Kimchi Based Hotpot Buffet</td>\n",
       "      <td></td>\n",
       "      <td>Jasmine Low</td>\n",
       "      <td>6</td>\n",
       "      <td>187</td>\n",
       "      <td>Aug 28, 2012</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>My Must Have Whenever I'm Here For Steamboat</td>\n",
       "      <td></td>\n",
       "      <td>June Lee</td>\n",
       "      <td>8</td>\n",
       "      <td>989</td>\n",
       "      <td>Jun 29, 2012</td>\n",
       "      <td>/sukiya</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63921 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                     Glad It’s Back!   \n",
       "1                                 Yuzu Ochazuke ($24)   \n",
       "2                                Belly Roll Mee ($15)   \n",
       "3                                Samurai Kueh Pie Tee   \n",
       "0                         Build Your Own Bowl (Small)   \n",
       "..                                                ...   \n",
       "7   Yummy meat galore shabu shabu buffet for the s...   \n",
       "8   Our #steamboat #buffet #dinner before watching...   \n",
       "9   My favorite whenever im here for steamboat! Lo...   \n",
       "10            Sukiyaki and Kimchi Based Hotpot Buffet   \n",
       "11       My Must Have Whenever I'm Here For Steamboat   \n",
       "\n",
       "                                                 Body      Reviewer  \\\n",
       "0   We ordered two appetisers and four main dishes...     Sofina Ng   \n",
       "1   This rice in soup dish is the first one I’ve h...         Jan L   \n",
       "2   The successor to Uncle Kiisu, Babasan’s menu d...       Dex Neo   \n",
       "3   This was like a little bomb that exploded with...   Komal Salve   \n",
       "0   Most salad/grain bowls serve up similar stuff ...       Nom Nom   \n",
       "..                                                ...           ...   \n",
       "7   Yummy meat galore shabu shabu buffet for the s...    Alison Ong   \n",
       "8   Our #steamboat #buffet #dinner before watching...  Benjamin Yeo   \n",
       "9                                                          June Lee   \n",
       "10                                                      Jasmine Low   \n",
       "11                                                         June Lee   \n",
       "\n",
       "   Reviewer_Level Reviewer_NumReviews     ReviewDateTime  \\\n",
       "0               3                   9            10m ago   \n",
       "1               3                  10             5d ago   \n",
       "2               8                 958   Oct 24 at 5:42pm   \n",
       "3               7                 208  Oct 23 at 10:06am   \n",
       "0               3                  15  Oct 25 at 10:13pm   \n",
       "..            ...                 ...                ...   \n",
       "7               7                 229       Dec 16, 2013   \n",
       "8               6                 170        Jun 7, 2013   \n",
       "9               8                 989       Aug 29, 2012   \n",
       "10              6                 187       Aug 28, 2012   \n",
       "11              8                 989       Jun 29, 2012   \n",
       "\n",
       "                 Restaurant                                  Food  \\\n",
       "0   /babasan-by-uncle-kiisu                            beer,fruit   \n",
       "1   /babasan-by-uncle-kiisu                                  rice   \n",
       "2   /babasan-by-uncle-kiisu  crispy pork,mee siam,pork,pork belly   \n",
       "3   /babasan-by-uncle-kiisu  fish,fish roe,rice,roe,seafood,unagi   \n",
       "0                     /yobo   brown rice,cream,pumpkin,rice,salad   \n",
       "..                      ...                                   ...   \n",
       "7                   /sukiya                 earl,meat,shabu shabu   \n",
       "8                   /sukiya                         steamboat,tea   \n",
       "9                   /sukiya                                         \n",
       "10                  /sukiya                                         \n",
       "11                  /sukiya                                         \n",
       "\n",
       "                                     RestaurantReview  \\\n",
       "0   we ordered two appetisers and four main dishes...   \n",
       "1   boy did it impress! perfect harmonious blend o...   \n",
       "2   the successor to uncle kiisu, babasan’s menu d...   \n",
       "3   this was like a little bomb that exploded with...   \n",
       "0   but i really enjoyed the broccoli puree served...   \n",
       "..                                                ...   \n",
       "7                                                       \n",
       "8                            our    before watching     \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "\n",
       "                                           FoodReview  \\\n",
       "0   kronenbourg blanc beer was very enjoyable too....   \n",
       "1   this rice in soup dish is the first one i’ve h...   \n",
       "2   i was seriously wondering how they would pull ...   \n",
       "3   i'm not a big fan of the seafoody taste loved ...   \n",
       "0   most salad/grain bowls serve up similar stuff ...   \n",
       "..                                                ...   \n",
       "7   yummy meat galore shabu shabu buffet for the s...   \n",
       "8                                                       \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "\n",
       "                             RestaurantFeature(spacy)  \\\n",
       "0     main,unique,boasting,manifested,creative,strong   \n",
       "1   impress,perfect,harmonious,fresh,generous,serv...   \n",
       "2   dreamt,good,sounds,heavy,provided,cut,amazingl...   \n",
       "3              little,exploded,eating,try,super worth   \n",
       "0                                      enjoyed,served   \n",
       "..                                                ...   \n",
       "7                                                       \n",
       "8                                            watching   \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "\n",
       "                                   FoodFeature(spacy)  \n",
       "0                                enjoyable,sweet,mild  \n",
       "1                                          great,good  \n",
       "2   seriously wondering,pull,crispy,stuffed,tender...  \n",
       "3                             big,loved,flying,smooth  \n",
       "0   salad,serve,similar,creamy,paired,brown,roaste...  \n",
       "..                                                ...  \n",
       "7                                            early,b4  \n",
       "8                                                      \n",
       "9                                                      \n",
       "10                                                     \n",
       "11                                                     \n",
       "\n",
       "[63921 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Class prediction on Burpple reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 positive sentiments\n",
      "         Word  Coefficient\n",
      "         good     5.394372\n",
      "         nice     4.664474\n",
      "         best     4.602491\n",
      "         love     4.413196\n",
      "        great     4.370333\n",
      "    delicious     4.316622\n",
      "        yummy     3.623320\n",
      "      perfect     3.196048\n",
      "       crispy     3.189819\n",
      "   definitely     2.982767\n",
      "      amazing     2.850342\n",
      "        fresh     2.796694\n",
      "       smooth     2.768042\n",
      "      overall     2.734124\n",
      "         rich     2.709265\n",
      "        tasty     2.668799\n",
      "    favourite     2.658364\n",
      "        right     2.600073\n",
      "   refreshing     2.551020\n",
      "        loved     2.439449\n",
      "       served     2.406420\n",
      "        lunch     2.390151\n",
      "          tad     2.295448\n",
      "         eggs     2.246962\n",
      "       dishes     2.233829\n",
      "       tender     2.224399\n",
      "      enjoyed     2.116993\n",
      "          bit     2.110187\n",
      "       highly     2.052429\n",
      "        comes     2.045065\n",
      "      awesome     2.008492\n",
      "         soft     1.982405\n",
      "        spicy     1.879361\n",
      "   affordable     1.870659\n",
      "    singapore     1.862325\n",
      "          try     1.857290\n",
      "    available     1.825593\n",
      "        fried     1.801428\n",
      "       creamy     1.799915\n",
      "      grilled     1.797827\n",
      "       unique     1.790075\n",
      "     fragrant     1.774877\n",
      "         goes     1.764652\n",
      "    perfectly     1.749369\n",
      "       nicely     1.711428\n",
      "         wait     1.700487\n",
      "      dessert     1.674480\n",
      "        liked     1.656259\n",
      "     friendly     1.650308\n",
      "       little     1.637272\n",
      "       topped     1.620807\n",
      "          yum     1.573178\n",
      "   satisfying     1.571572\n",
      "        happy     1.566999\n",
      "       simple     1.563029\n",
      "        toast     1.545015\n",
      "        place     1.537643\n",
      " surprisingly     1.525191\n",
      "          day     1.511209\n",
      "      savoury     1.505735\n",
      "        super     1.505652\n",
      "       filled     1.505327\n",
      "          ice     1.485617\n",
      "         glad     1.478884\n",
      "         meal     1.469778\n",
      "        moist     1.455753\n",
      "       thanks     1.438428\n",
      "      freshly     1.402162\n",
      "      friends     1.401424\n",
      "    excellent     1.386353\n",
      "        thank     1.357607\n",
      "         melt     1.341707\n",
      "    addictive     1.338751\n",
      "        belly     1.334358\n",
      "       course     1.332627\n",
      "        share     1.325824\n",
      "        latte     1.322853\n",
      "     balanced     1.321337\n",
      "        enjoy     1.317592\n",
      "      sharing     1.306566\n",
      "       dinner     1.305114\n",
      "        crisp     1.302686\n",
      "           ve     1.290087\n",
      "        cream     1.282638\n",
      "        salad     1.258796\n",
      "        juicy     1.249610\n",
      "     aromatic     1.241179\n",
      "         duck     1.234113\n",
      "      seafood     1.226605\n",
      "     location     1.224546\n",
      "          mee     1.220271\n",
      "       having     1.219891\n",
      "       sunday     1.218537\n",
      "         haha     1.212268\n",
      "        sushi     1.210111\n",
      "        baked     1.203783\n",
      "         deal     1.196113\n",
      "    surprised     1.182933\n",
      "     slightly     1.182278\n",
      "           sg     1.166381\n",
      "\n",
      "Top 100 negative sentiments\n",
      "           Word  Coefficient\n",
      "           bits    -1.907031\n",
      "        anymore    -1.908137\n",
      "       supposed    -1.922992\n",
      "          smell    -1.924648\n",
      "             28    -1.927388\n",
      "         unless    -1.939272\n",
      "        texture    -1.950320\n",
      "           nope    -1.963873\n",
      "             评分    -1.966172\n",
      "        strange    -1.969445\n",
      "        totally    -1.986729\n",
      "           pass    -1.995977\n",
      "          cheap    -2.016940\n",
      "            meh    -2.025179\n",
      "     overcooked    -2.042444\n",
      "      extremely    -2.071586\n",
      "            veg    -2.087165\n",
      "             40    -2.112784\n",
      "          didnt    -2.116668\n",
      "           crab    -2.120391\n",
      "            isn    -2.125166\n",
      "         liking    -2.126121\n",
      "     aftertaste    -2.179060\n",
      "         looked    -2.199174\n",
      "         hardly    -2.216371\n",
      "          mushy    -2.243856\n",
      "         hoping    -2.248100\n",
      "     artificial    -2.248959\n",
      "      expecting    -2.255821\n",
      "           oily    -2.274355\n",
      "          ended    -2.293979\n",
      "          steam    -2.299542\n",
      "  underwhelming    -2.321581\n",
      "           date    -2.333156\n",
      "           look    -2.378991\n",
      "      overrated    -2.382179\n",
      "         couldn    -2.423937\n",
      "        ordered    -2.477944\n",
      "         minced    -2.491305\n",
      "        changed    -2.509773\n",
      "           weak    -2.533026\n",
      "         wanted    -2.534019\n",
      "           fail    -2.571034\n",
      "        concept    -2.591406\n",
      "           wasn    -2.617356\n",
      "             00    -2.683989\n",
      "            sad    -2.689776\n",
      "           left    -2.711320\n",
      "           hard    -2.736646\n",
      "         melted    -2.745758\n",
      "            won    -2.746954\n",
      "          burnt    -2.775078\n",
      "         barely    -2.785705\n",
      "          salty    -2.799075\n",
      "         edible    -2.813150\n",
      "         watery    -2.815888\n",
      "       expected    -2.817390\n",
      "        alright    -2.857953\n",
      "       terrible    -2.872300\n",
      "         tossed    -3.107496\n",
      "         lacked    -3.150950\n",
      "             50    -3.179794\n",
      "           idea    -3.181135\n",
      "        instead    -3.217622\n",
      "        lacking    -3.220369\n",
      "             10    -3.241360\n",
      "        picture    -3.244711\n",
      "            did    -3.245014\n",
      "          worst    -3.257628\n",
      "       thinking    -3.364007\n",
      "            dry    -3.448174\n",
      "          sorry    -3.451429\n",
      "          guess    -3.530421\n",
      "           hype    -3.545304\n",
      "          weird    -3.562320\n",
      "           skip    -3.657571\n",
      "         tasted    -3.700199\n",
      "          money    -3.802387\n",
      "        thought    -3.805666\n",
      "           poor    -3.807352\n",
      "     overpriced    -3.914578\n",
      "         wouldn    -3.924552\n",
      "           felt    -3.935622\n",
      "           okay    -4.408977\n",
      "           didn    -4.437808\n",
      "          stick    -4.486323\n",
      "          taste    -4.518533\n",
      "           flat    -4.662680\n",
      "       mediocre    -5.028729\n",
      "          maybe    -5.208893\n",
      "      tasteless    -5.539364\n",
      "          sadly    -5.733072\n",
      "            bad    -5.955212\n",
      "             ok    -5.955836\n",
      " disappointment    -5.983559\n",
      "  unfortunately    -6.652396\n",
      "         return    -6.817475\n",
      "          bland    -7.388773\n",
      "   disappointed    -8.212479\n",
      "  disappointing   -11.463719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#=====================================================#\n",
    "# Load the model from disk\n",
    "#=====================================================#\n",
    "filename = 'lr_model.sav'\n",
    "loaded_model = joblib.load(filename) #load model \n",
    "\n",
    "\n",
    "#=====================================================#\n",
    "# Extract details from csv file\n",
    "#=====================================================#\n",
    "#data = pd.read_csv('reviews.csv',index_col=[0])\n",
    "#data = data.fillna('-') # fill none with '-'\n",
    "#data.replace({'\\n': ''}, inplace=True, regex=True) # remove break line\n",
    "\n",
    "#X = data['Review']\n",
    "X = data['Body']\n",
    "data['SentimentClass'] = loaded_model.predict(X)\n",
    "y = data['SentimentClass']\n",
    "\n",
    "#=====================================================#\n",
    "# Train the model (after sentiment score only)\n",
    "#=====================================================#\n",
    "tfidf = TfidfVectorizer(stop_words = 'english') #for converting reviews to matrix of TF-IDF features\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs') #using logistic regression as prediction model\n",
    "clf_pipeline = Pipeline([('tfidf', tfidf), ('lr', lr)]) #create pipeline of vectorizing and prediction steps\n",
    "clf_pipeline.fit(X, y) #fit training data into pipeline\n",
    "\n",
    "\n",
    "#=====================================================#\n",
    "# Extract postive and negative sentiments\n",
    "#=====================================================#\n",
    "num = 100 #number of features\n",
    "\n",
    "word = tfidf.get_feature_names() #get sentiment words/ features\n",
    "coef = clf_pipeline.named_steps['lr'].coef_.tolist()[0] #get coefficient of features (feature importances) \n",
    "coeff_df = pd.DataFrame({'Word' : word, 'Coefficient' : coef})\n",
    "coeff_df = coeff_df.sort_values(['Coefficient'], ascending=[False]) #sort descending by coefficient.\n",
    "\n",
    "print('\\n'+'Top {} positive sentiments'.format(num))\n",
    "print(coeff_df.head(num).to_string(index=False))\n",
    "print('\\n'+'Top {} negative sentiments'.format(num))   \n",
    "print(coeff_df.tail(num).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================#\n",
    "# Export to csv\n",
    "#=====================================================#\n",
    "data.to_csv('restaurant_reviews_withsentiment.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features using VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
    "\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. Support for emoji recognition (UTF-8 encoded).\n",
    "- https://github.com/cjhutto/vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#=====================================================#\n",
    "# Extract features from reviews\n",
    "#=====================================================#\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# load analyzer and update lexicon \n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "analyzer.lexicon.update({u'affordable': 2,\n",
    "                         u'appetising': 2,\n",
    "                         u'tasteless': -2})\n",
    "\n",
    "# Get list of words to be removed from reviews\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "remove_words = [\"n't\",\"'m\",\"'s\",\"'ll\",\"'ve\",\"'d\",\"'re\",\"n’t\",\"’m\",\"’s\",\"’ll\",\"’ve\",\"’d\",\"’re\"]\n",
    "\n",
    "def features_vader(col_name):\n",
    "    # For each word in the review\n",
    "    feature_list = []\n",
    "    score_list = []\n",
    "    text_list = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        rev = data[col_name].iloc[i]\n",
    "        #rev = rev.replace('and ', '').replace('& ', '')\n",
    "        doc = nlp(rev)\n",
    "        feature = []    \n",
    "\n",
    "        # For each word in the review\n",
    "        for w in doc:\n",
    "\n",
    "            # Check if word not from stop words\n",
    "            if w.text.lower() not in stop_words and w.text.lower() not in remove_words:\n",
    "                extract = None\n",
    "                text_list.append(w.text.lower())\n",
    "\n",
    "                # Check for more than two words    \n",
    "                if len(text_list) > 2: \n",
    "\n",
    "                    # Rule 1\n",
    "                    if (analyzer.polarity_scores(w.text)['compound']) >= 0.1 or (analyzer.polarity_scores(w.text)['compound']) <= -0.1:\n",
    "                        extract = text_list[-1]\n",
    "\n",
    "                    if extract != None:\n",
    "                        feature.append(extract)\n",
    "                        \n",
    "        feature = list(dict.fromkeys(feature)) # remove duplicates\n",
    "        feature_list.append(','.join(feature)) # create list of sentiment feature for each review\n",
    "\n",
    "        score = analyzer.polarity_scores(' '.join(rev)) # get sentiment score\n",
    "        score_list.append(score['compound']) # create list of sentiment score for each review\n",
    "        \n",
    "        '''\n",
    "        The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according\n",
    "        to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive).\n",
    "        '''\n",
    "             \n",
    "    return feature_list, score_list\n",
    "\n",
    "\n",
    "#=====================================================#\n",
    "# Store features into dataframe\n",
    "#=====================================================#\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "data['RestaurantFeature(vader)'], data['RestaurantScore(vader)'] = features_vader('RestaurantReview')\n",
    "data['FoodFeature(vader)'], data['FoodScore(vader)']  = features_vader('FoodReview')\n",
    "\n",
    "print('Time taken:', convert(time.time()-start))\n",
    "\n",
    "\n",
    "#=====================================================#\n",
    "# Export to csv\n",
    "#=====================================================#\n",
    "data.to_csv('restaurant_reviews_withsentiment.csv')\n",
    "\n",
    "data\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
