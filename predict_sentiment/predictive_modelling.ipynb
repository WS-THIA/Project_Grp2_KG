{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train sentiment prediction model based on amazon food reviews\n",
    "This dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n",
    "\n",
    "https://www.kaggle.com/snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935205347888516\n",
      "\n",
      "Top 20 positive sentiments\n",
      "       Word  Coefficient\n",
      "      great    14.056236\n",
      "  delicious    12.569577\n",
      "       best    11.917344\n",
      "    perfect    10.765441\n",
      "  excellent     9.978509\n",
      "      loves     9.678879\n",
      "     highly     8.902305\n",
      "       love     8.513440\n",
      "  wonderful     8.197428\n",
      "    amazing     7.540611\n",
      " pleasantly     7.471089\n",
      "       good     7.316470\n",
      "     hooked     7.281038\n",
      "    awesome     7.221646\n",
      "       nice     7.099952\n",
      "   favorite     6.921111\n",
      "    pleased     6.900758\n",
      "      yummy     6.697903\n",
      "     smooth     6.697484\n",
      "       glad     6.421410\n",
      "\n",
      "Top 20 negative sentiments\n",
      "           Word  Coefficient\n",
      "          waste    -5.656552\n",
      "           yuck    -5.713675\n",
      "   unacceptable    -5.917392\n",
      "    undrinkable    -5.942775\n",
      "          worse    -6.134979\n",
      "          stale    -6.234432\n",
      "     disgusting    -6.409609\n",
      "      tasteless    -6.449217\n",
      "           weak    -6.489440\n",
      "          bland    -6.605334\n",
      "          threw    -6.798688\n",
      "         return    -6.892879\n",
      "  unfortunately    -7.706355\n",
      "       horrible    -7.912724\n",
      " disappointment    -8.059012\n",
      "          awful    -8.314880\n",
      "   disappointed    -8.523823\n",
      "       terrible    -9.373132\n",
      "  disappointing    -9.852226\n",
      "          worst   -11.512352\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#=====================================================#\n",
    "# Create train and test dataset from kaggle data\n",
    "#=====================================================#\n",
    "df = pd.read_csv('Amazon_food.csv') #read csv\n",
    "amazon = df[df['Score'] != 3] #remove neutral score/ feedback rating (i.e. =3)\n",
    "X = amazon['Text'] #extract reviews\n",
    "y = amazon['Score'].map({1:0, 2:0, 4:1, 5:1}) #extract score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state=0) # 80/20 split\n",
    "\n",
    "\n",
    "#=====================================================#\n",
    "# Train the model\n",
    "#=====================================================#\n",
    "tfidf = TfidfVectorizer(stop_words = 'english') #for converting reviews to matrix of TF-IDF features\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs') #using logistic regression as prediction model\n",
    "clf_pipeline = Pipeline([('tfidf', tfidf), ('lr', lr)]) #create pipeline of vectorizing and prediction steps\n",
    "clf_pipeline.fit(X_train, y_train) #fit training data into pipeline\n",
    "print ('Accuracy: {}'.format(clf_pipeline.score(X_test, y_test))) #get accuracy\n",
    "\n",
    "\n",
    "#=====================================================#\n",
    "# Save the model to disk\n",
    "#=====================================================#\n",
    "filename = 'lr_model.sav'\n",
    "joblib.dump(clf_pipeline, filename) #persist model into file \n",
    "\n",
    "\n",
    "#=====================================================#\n",
    "# Extract postive and negative sentiments\n",
    "#=====================================================#\n",
    "num = 20 #number of features\n",
    "\n",
    "word = tfidf.get_feature_names() #get sentiment words/ features\n",
    "coef = clf_pipeline.named_steps['lr'].coef_.tolist()[0] #get coefficient of features (feature importances) \n",
    "coeff_df = pd.DataFrame({'Word' : word, 'Coefficient' : coef})\n",
    "coeff_df = coeff_df.sort_values(['Coefficient'], ascending=[False]) #sort descending by coefficient.\n",
    "\n",
    "print('\\n'+'Top {} positive sentiments'.format(num))\n",
    "print(coeff_df.head(num).to_string(index=False))\n",
    "print('\\n'+'Top {} negative sentiments'.format(num))   \n",
    "print(coeff_df.tail(num).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
